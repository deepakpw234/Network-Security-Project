[ 2024-11-27 20:16:05,446 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2024-11-27 20:16:05,453 ] 107 dagshub - INFO - Accessing as deepakpw234
[ 2024-11-27 20:16:06,388 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/deepakpw234/Network-Security-Project "HTTP/1.1 200 OK"
[ 2024-11-27 20:16:09,556 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2024-11-27 20:16:09,562 ] 107 dagshub - INFO - Initialized MLflow to track repo "deepakpw234/Network-Security-Project"
[ 2024-11-27 20:16:09,563 ] 107 dagshub - INFO - Repository deepakpw234/Network-Security-Project initialized!
[ 2024-11-27 21:14:20,311 ] 30 root - INFO - Start data ingestion
[ 2024-11-27 21:14:20,311 ] 23 root - INFO - Data Ingestion constructor initaited
[ 2024-11-27 21:14:20,311 ] 86 root - INFO - Calling data from mongo DB
[ 2024-11-27 21:14:25,163 ] 88 root - INFO - MongoDB data is loaded into to dataframe
[ 2024-11-27 21:14:25,163 ] 89 root - INFO - Raw data saving in featuer store is started
[ 2024-11-27 21:14:25,238 ] 91 root - INFO - Raw data is saved in feature store
[ 2024-11-27 21:14:25,238 ] 92 root - INFO - Train test split started
[ 2024-11-27 21:14:25,326 ] 94 root - INFO - Train test completed and train and test csv's saved in ingested store
[ 2024-11-27 21:14:25,326 ] 98 root - INFO - Train and test file path saved in the artifact
[ 2024-11-27 21:14:25,327 ] 33 root - INFO - data ingestion completed and data artifact: DataIngestionartifact(train_file_path='artifacts\\27_11_2024_20_16_00\\data_ingestion\\ingested\\train.csv', test_file_path='artifacts\\27_11_2024_20_16_00\\data_ingestion\\ingested\\test.csv')
[ 2024-11-27 21:14:25,327 ] 42 root - INFO - Start data validation
[ 2024-11-27 21:14:25,403 ] 40 root - INFO - required columns are 31
[ 2024-11-27 21:14:25,403 ] 41 root - INFO - dataframe has columns 31
[ 2024-11-27 21:14:25,403 ] 40 root - INFO - required columns are 31
[ 2024-11-27 21:14:25,404 ] 41 root - INFO - dataframe has columns 31
[ 2024-11-27 21:14:25,565 ] 45 root - INFO - data validation completed and data artifact: DataValidationartifact(validation_status=True, valid_train_file_path='artifacts\\27_11_2024_20_16_00\\data_validation\\validated\\train.csv', valid_test_file_path='artifacts\\27_11_2024_20_16_00\\data_validation\\validated\\test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='artifacts\\27_11_2024_20_16_00\\data_validation\\drift_report\\report.yaml')
[ 2024-11-27 21:14:25,565 ] 53 root - INFO - Start data transformation
[ 2024-11-27 21:14:25,565 ] 26 root - INFO - Data Transfomation class is initiated with init constructor
[ 2024-11-27 21:14:25,565 ] 55 root - INFO - Initiate the data transformation with initiate function
[ 2024-11-27 21:14:25,626 ] 63 root - INFO - Input and target columns created for training dataframe
[ 2024-11-27 21:14:25,627 ] 69 root - INFO - Input and target columns craeted for test dataframe
[ 2024-11-27 21:14:25,640 ] 42 root - INFO - Saving into numpy array
[ 2024-11-27 21:14:25,645 ] 42 root - INFO - Saving into numpy array
[ 2024-11-27 21:14:25,646 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:14:25,649 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:14:25,653 ] 56 root - INFO - data transformation completed and data artifact: DataTransformationArtifact(transformed_object_file_path='artifacts\\27_11_2024_20_16_00\\data_transformation\\transformed_object\\preprocessing.pkl', transformed_train_file_path='artifacts\\27_11_2024_20_16_00\\data_transformation\\transformed\\train.npy', transformed_test_file_path='artifacts\\27_11_2024_20_16_00\\data_transformation\\transformed\\test.npy')
[ 2024-11-27 21:14:25,653 ] 65 root - INFO - Start model trainer
[ 2024-11-27 21:14:25,653 ] 75 root - INFO - Numpy array is loading
[ 2024-11-27 21:14:25,662 ] 75 root - INFO - Numpy array is loading
[ 2024-11-27 21:16:40,617 ] 64 root - INFO - pickle object is loading
[ 2024-11-27 21:16:40,626 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:16:40,659 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:16:40,689 ] 68 root - INFO - Model trainer completed and data artifact: ModelTrainerArtifact(trained_model_path='artifacts\\27_11_2024_20_16_00\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=np.float64(0.9915504428382368), precision_score=np.float64(0.9896362527941476), recall_score=np.float64(0.9934720522235823)), test_metric_artifact=ClassificationMetricArtifact(f1_score=np.float64(0.9722882026920031), precision_score=np.float64(0.966168371361133), recall_score=np.float64(0.9784860557768924)))
[ 2024-11-27 21:23:14,906 ] 30 root - INFO - Start data ingestion
[ 2024-11-27 21:23:14,906 ] 23 root - INFO - Data Ingestion constructor initaited
[ 2024-11-27 21:23:14,907 ] 86 root - INFO - Calling data from mongo DB
[ 2024-11-27 21:23:17,365 ] 88 root - INFO - MongoDB data is loaded into to dataframe
[ 2024-11-27 21:23:17,366 ] 89 root - INFO - Raw data saving in featuer store is started
[ 2024-11-27 21:23:17,452 ] 91 root - INFO - Raw data is saved in feature store
[ 2024-11-27 21:23:17,453 ] 92 root - INFO - Train test split started
[ 2024-11-27 21:23:17,528 ] 94 root - INFO - Train test completed and train and test csv's saved in ingested store
[ 2024-11-27 21:23:17,528 ] 98 root - INFO - Train and test file path saved in the artifact
[ 2024-11-27 21:23:17,528 ] 33 root - INFO - data ingestion completed and data artifact: DataIngestionartifact(train_file_path='artifacts\\27_11_2024_20_16_00\\data_ingestion\\ingested\\train.csv', test_file_path='artifacts\\27_11_2024_20_16_00\\data_ingestion\\ingested\\test.csv')
[ 2024-11-27 21:23:17,529 ] 42 root - INFO - Start data validation
[ 2024-11-27 21:23:17,584 ] 40 root - INFO - required columns are 31
[ 2024-11-27 21:23:17,584 ] 41 root - INFO - dataframe has columns 31
[ 2024-11-27 21:23:17,584 ] 40 root - INFO - required columns are 31
[ 2024-11-27 21:23:17,585 ] 41 root - INFO - dataframe has columns 31
[ 2024-11-27 21:23:17,752 ] 45 root - INFO - data validation completed and data artifact: DataValidationartifact(validation_status=True, valid_train_file_path='artifacts\\27_11_2024_20_16_00\\data_validation\\validated\\train.csv', valid_test_file_path='artifacts\\27_11_2024_20_16_00\\data_validation\\validated\\test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='artifacts\\27_11_2024_20_16_00\\data_validation\\drift_report\\report.yaml')
[ 2024-11-27 21:23:17,752 ] 53 root - INFO - Start data transformation
[ 2024-11-27 21:23:17,752 ] 26 root - INFO - Data Transfomation class is initiated with init constructor
[ 2024-11-27 21:23:17,753 ] 55 root - INFO - Initiate the data transformation with initiate function
[ 2024-11-27 21:23:17,803 ] 63 root - INFO - Input and target columns created for training dataframe
[ 2024-11-27 21:23:17,804 ] 69 root - INFO - Input and target columns craeted for test dataframe
[ 2024-11-27 21:23:17,816 ] 42 root - INFO - Saving into numpy array
[ 2024-11-27 21:23:17,820 ] 42 root - INFO - Saving into numpy array
[ 2024-11-27 21:23:17,822 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:23:17,826 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:23:17,830 ] 56 root - INFO - data transformation completed and data artifact: DataTransformationArtifact(transformed_object_file_path='artifacts\\27_11_2024_20_16_00\\data_transformation\\transformed_object\\preprocessing.pkl', transformed_train_file_path='artifacts\\27_11_2024_20_16_00\\data_transformation\\transformed\\train.npy', transformed_test_file_path='artifacts\\27_11_2024_20_16_00\\data_transformation\\transformed\\test.npy')
[ 2024-11-27 21:23:17,830 ] 65 root - INFO - Start model trainer
[ 2024-11-27 21:23:17,830 ] 75 root - INFO - Numpy array is loading
[ 2024-11-27 21:23:17,839 ] 75 root - INFO - Numpy array is loading
[ 2024-11-27 21:25:25,667 ] 64 root - INFO - pickle object is loading
[ 2024-11-27 21:25:25,676 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:25:25,682 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:25:25,690 ] 68 root - INFO - Model trainer completed and data artifact: ModelTrainerArtifact(trained_model_path='artifacts\\27_11_2024_20_16_00\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=np.float64(0.9914390542193233), precision_score=np.float64(0.9906313645621181), recall_score=np.float64(0.9922480620155039)), test_metric_artifact=ClassificationMetricArtifact(f1_score=np.float64(0.9726732673267326), precision_score=np.float64(0.9669291338582677), recall_score=np.float64(0.9784860557768924)))
