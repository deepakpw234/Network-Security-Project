[ 2024-11-27 18:15:25,273 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2024-11-27 18:15:25,279 ] 107 dagshub - INFO - Accessing as deepakpw234
[ 2024-11-27 18:15:25,644 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/deepakpw234/Network-Security-Project "HTTP/1.1 200 OK"
[ 2024-11-27 18:15:25,976 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2024-11-27 18:15:25,978 ] 107 dagshub - INFO - Initialized MLflow to track repo "deepakpw234/Network-Security-Project"
[ 2024-11-27 18:15:25,986 ] 107 dagshub - INFO - Repository deepakpw234/Network-Security-Project initialized!
[ 2024-11-27 18:17:47,531 ] 30 root - INFO - Start data ingestion
[ 2024-11-27 18:17:47,532 ] 23 root - INFO - Data Ingestion constructor initaited
[ 2024-11-27 18:17:47,532 ] 86 root - INFO - Calling data from mongo DB
[ 2024-11-27 18:17:48,614 ] 88 root - INFO - MongoDB data is loaded into to dataframe
[ 2024-11-27 18:17:48,614 ] 89 root - INFO - Raw data saving in featuer store is started
[ 2024-11-27 18:17:48,667 ] 91 root - INFO - Raw data is saved in feature store
[ 2024-11-27 18:17:48,668 ] 92 root - INFO - Train test split started
[ 2024-11-27 18:17:48,731 ] 94 root - INFO - Train test completed and train and test csv's saved in ingested store
[ 2024-11-27 18:17:48,731 ] 98 root - INFO - Train and test file path saved in the artifact
[ 2024-11-27 18:17:48,731 ] 33 root - INFO - data ingestion completed and data artifact: DataIngestionartifact(train_file_path='artifacts\\27_11_2024_18_15_22\\data_ingestion\\ingested\\train.csv', test_file_path='artifacts\\27_11_2024_18_15_22\\data_ingestion\\ingested\\test.csv')
[ 2024-11-27 18:17:48,732 ] 42 root - INFO - Start data validation
[ 2024-11-27 18:17:48,795 ] 40 root - INFO - required columns are 31
[ 2024-11-27 18:17:48,795 ] 41 root - INFO - dataframe has columns 31
[ 2024-11-27 18:17:48,795 ] 40 root - INFO - required columns are 31
[ 2024-11-27 18:17:48,795 ] 41 root - INFO - dataframe has columns 31
[ 2024-11-27 18:17:48,917 ] 45 root - INFO - data validation completed and data artifact: DataValidationartifact(validation_status=True, valid_train_file_path='artifacts\\27_11_2024_18_15_22\\data_validation\\validated\\train.csv', valid_test_file_path='artifacts\\27_11_2024_18_15_22\\data_validation\\validated\\test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='artifacts\\27_11_2024_18_15_22\\data_validation\\drift_report\\report.yaml')
[ 2024-11-27 18:17:48,917 ] 53 root - INFO - Start data transformation
[ 2024-11-27 18:17:48,918 ] 26 root - INFO - Data Transfomation class is initiated with init constructor
[ 2024-11-27 18:17:48,918 ] 55 root - INFO - Initiate the data transformation with initiate function
[ 2024-11-27 18:17:48,961 ] 63 root - INFO - Input and target columns created for training dataframe
[ 2024-11-27 18:17:48,962 ] 69 root - INFO - Input and target columns craeted for test dataframe
[ 2024-11-27 18:17:48,969 ] 42 root - INFO - Saving into numpy array
[ 2024-11-27 18:17:48,972 ] 42 root - INFO - Saving into numpy array
[ 2024-11-27 18:17:48,973 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 18:17:48,976 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 18:17:48,979 ] 56 root - INFO - data transformation completed and data artifact: DataTransformationArtifact(transformed_object_file_path='artifacts\\27_11_2024_18_15_22\\data_transformation\\transformed_object\\preprocessing.pkl', transformed_train_file_path='artifacts\\27_11_2024_18_15_22\\data_transformation\\transformed\\train.npy', transformed_test_file_path='artifacts\\27_11_2024_18_15_22\\data_transformation\\transformed\\test.npy')
[ 2024-11-27 18:17:48,979 ] 65 root - INFO - Start model trainer
[ 2024-11-27 18:17:48,980 ] 75 root - INFO - Numpy array is loading
[ 2024-11-27 18:17:48,989 ] 75 root - INFO - Numpy array is loading
[ 2024-11-27 18:30:24,951 ] 64 root - INFO - pickle object is loading
[ 2024-11-27 18:30:24,958 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 18:30:24,976 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 18:30:24,996 ] 68 root - INFO - Model trainer completed and data artifact: ModelTrainerArtifact(trained_model_path='artifacts\\27_11_2024_18_15_22\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=np.float64(0.9915504428382368), precision_score=np.float64(0.9896362527941476), recall_score=np.float64(0.9934720522235823)), test_metric_artifact=ClassificationMetricArtifact(f1_score=np.float64(0.9716088328075709), precision_score=np.float64(0.9617486338797814), recall_score=np.float64(0.9816733067729083)))
