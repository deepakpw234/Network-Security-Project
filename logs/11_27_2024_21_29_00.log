[ 2024-11-27 21:29:08,190 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2024-11-27 21:29:08,197 ] 107 dagshub - INFO - Accessing as deepakpw234
[ 2024-11-27 21:29:08,702 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/repos/deepakpw234/Network-Security-Project "HTTP/1.1 200 OK"
[ 2024-11-27 21:29:09,890 ] 1038 httpx - INFO - HTTP Request: GET https://dagshub.com/api/v1/user "HTTP/1.1 200 OK"
[ 2024-11-27 21:29:09,893 ] 107 dagshub - INFO - Initialized MLflow to track repo "deepakpw234/Network-Security-Project"
[ 2024-11-27 21:29:09,909 ] 107 dagshub - INFO - Repository deepakpw234/Network-Security-Project initialized!
[ 2024-11-27 21:29:45,657 ] 30 root - INFO - Start data ingestion
[ 2024-11-27 21:29:45,658 ] 23 root - INFO - Data Ingestion constructor initaited
[ 2024-11-27 21:29:45,658 ] 86 root - INFO - Calling data from mongo DB
[ 2024-11-27 21:29:50,764 ] 88 root - INFO - MongoDB data is loaded into to dataframe
[ 2024-11-27 21:29:50,765 ] 89 root - INFO - Raw data saving in featuer store is started
[ 2024-11-27 21:29:50,824 ] 91 root - INFO - Raw data is saved in feature store
[ 2024-11-27 21:29:50,824 ] 92 root - INFO - Train test split started
[ 2024-11-27 21:29:50,884 ] 94 root - INFO - Train test completed and train and test csv's saved in ingested store
[ 2024-11-27 21:29:50,884 ] 98 root - INFO - Train and test file path saved in the artifact
[ 2024-11-27 21:29:50,885 ] 33 root - INFO - data ingestion completed and data artifact: DataIngestionartifact(train_file_path='artifacts\\27_11_2024_21_29_01\\data_ingestion\\ingested\\train.csv', test_file_path='artifacts\\27_11_2024_21_29_01\\data_ingestion\\ingested\\test.csv')
[ 2024-11-27 21:29:50,885 ] 42 root - INFO - Start data validation
[ 2024-11-27 21:29:50,940 ] 40 root - INFO - required columns are 31
[ 2024-11-27 21:29:50,940 ] 41 root - INFO - dataframe has columns 31
[ 2024-11-27 21:29:50,940 ] 40 root - INFO - required columns are 31
[ 2024-11-27 21:29:50,940 ] 41 root - INFO - dataframe has columns 31
[ 2024-11-27 21:29:51,078 ] 45 root - INFO - data validation completed and data artifact: DataValidationartifact(validation_status=True, valid_train_file_path='artifacts\\27_11_2024_21_29_01\\data_validation\\validated\\train.csv', valid_test_file_path='artifacts\\27_11_2024_21_29_01\\data_validation\\validated\\test.csv', invalid_train_file_path=None, invalid_test_file_path=None, drift_report_file_path='artifacts\\27_11_2024_21_29_01\\data_validation\\drift_report\\report.yaml')
[ 2024-11-27 21:29:51,079 ] 53 root - INFO - Start data transformation
[ 2024-11-27 21:29:51,079 ] 26 root - INFO - Data Transfomation class is initiated with init constructor
[ 2024-11-27 21:29:51,079 ] 55 root - INFO - Initiate the data transformation with initiate function
[ 2024-11-27 21:29:51,126 ] 63 root - INFO - Input and target columns created for training dataframe
[ 2024-11-27 21:29:51,127 ] 69 root - INFO - Input and target columns craeted for test dataframe
[ 2024-11-27 21:29:51,138 ] 42 root - INFO - Saving into numpy array
[ 2024-11-27 21:29:51,142 ] 42 root - INFO - Saving into numpy array
[ 2024-11-27 21:29:51,144 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:29:51,147 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:29:51,150 ] 56 root - INFO - data transformation completed and data artifact: DataTransformationArtifact(transformed_object_file_path='artifacts\\27_11_2024_21_29_01\\data_transformation\\transformed_object\\preprocessing.pkl', transformed_train_file_path='artifacts\\27_11_2024_21_29_01\\data_transformation\\transformed\\train.npy', transformed_test_file_path='artifacts\\27_11_2024_21_29_01\\data_transformation\\transformed\\test.npy')
[ 2024-11-27 21:29:51,150 ] 65 root - INFO - Start model trainer
[ 2024-11-27 21:29:51,150 ] 75 root - INFO - Numpy array is loading
[ 2024-11-27 21:29:51,158 ] 75 root - INFO - Numpy array is loading
[ 2024-11-27 21:31:55,627 ] 64 root - INFO - pickle object is loading
[ 2024-11-27 21:31:55,637 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:31:55,669 ] 53 root - INFO - Preprocessor is saving into pickle object
[ 2024-11-27 21:31:55,701 ] 68 root - INFO - Model trainer completed and data artifact: ModelTrainerArtifact(trained_model_path='artifacts\\27_11_2024_21_29_01\\model_trainer\\trained_model\\model.pkl', train_metric_artifact=ClassificationMetricArtifact(f1_score=np.float64(0.9915556007732221), precision_score=np.float64(0.9890399837629389), recall_score=np.float64(0.9940840473276213)), test_metric_artifact=ClassificationMetricArtifact(f1_score=np.float64(0.9707740916271722), precision_score=np.float64(0.9624119028974158), recall_score=np.float64(0.9792828685258964)))
